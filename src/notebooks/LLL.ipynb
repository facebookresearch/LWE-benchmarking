{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d19803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import jdata as jd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "from tabulate import tabulate\n",
    "from glob import glob\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from IPython.core.display import HTML\n",
    "display(HTML(\"<style>.container {width:90% !important;}</style>\"))\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6f0a5550",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"attachment:Screenshot%202022-08-01%20at%2013.49.35.png\" width=\"500\"/>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43d90b51",
   "metadata": {},
   "source": [
    "An LWE sample is a pair $(\\textbf{a}, b: = \\textbf{a}\\cdot \\textbf{s} + e)$, where $\\textbf{a} \\sim U(\\mathbb{Z}_q^N)$\n",
    ", $\\textbf{s} \\in \\mathbb{Z}_q$ is the secret and $e \\in \\mathbb{Z}_q$ is the error from a small distribution, e.g. $\\mathcal{N}(0,\\sigma^2)$ with $\\sigma=3.2$. We construct matrix $A_{N\\times N}$ with $\\textbf{a}$ as rows. \\\n",
    "Let $A' = \\begin{bmatrix}\n",
    "I_n & A \\\\\n",
    "0 & qI_n \n",
    "\\end{bmatrix}$. We run LLL on $A^{'}$, which finds an integer linear combinations of the rows that minimize the row norms. \\\n",
    "Denote the linear transformation (i.e., a change of basis, or a rotation) as matrix $R' = \\begin{bmatrix} R_{2N\\times N} & C_{2N\\times N}  \\end{bmatrix}$. \n",
    "We have $$ R'A' =  \\begin{bmatrix} R_{2N\\times N} & C_{2N\\times N}  \\end{bmatrix} \\begin{bmatrix}I_n & A \\\\ 0 & qI_n \\end{bmatrix} \n",
    "=\\begin{bmatrix} R & RA+qC  \\end{bmatrix} $$ \\\n",
    "where $qC$ effectively shifts the entries onto the interval $(-q/2,q/2)$. Hence, we get $RA$ which has small norm in the finite field. This is the purpose of the data preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b54af23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAb(N, Q, s):\n",
    "    print(f'state {np.random.get_state}')\n",
    "    print(f'N = {N}, Q = {Q}, s = {s}')\n",
    "    A = np.random.randint(0,Q,size=(N,N))\n",
    "    e = np.random.normal(0,3, N).astype(int)\n",
    "    b = (A@s + e)%Q\n",
    "    return A, b, e\n",
    "\n",
    "def get2N(N, Q, A, b, e):\n",
    "    AA = np.identity(2*N)\n",
    "    AA[:N, N:] = A\n",
    "    AA[N:, N:] *= Q\n",
    "\n",
    "    bb = np.zeros(2*N)\n",
    "    bb[:N] = b\n",
    "\n",
    "    ee = np.zeros(2*N)\n",
    "    ee[:N] = e\n",
    "    return AA, bb, ee\n",
    "\n",
    "N, Q = 5, 67\n",
    "A, b, e = getAb(N, Q, np.random.binomial(1,  0.2, size = N))\n",
    "AA, bb, ee = get2N(N, Q, A, b, e)\n",
    "print(AA)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e647b47b",
   "metadata": {},
   "source": [
    "Above is an example of the $A'$ matrix. \n",
    "### Now we present a demo of how LLL runs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8125fb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLL:\n",
    "    def __init__(self, Q = 251, delta = 0.75, right = True):\n",
    "        self.delta = delta\n",
    "        self.r = right\n",
    "        self.Q = Q\n",
    "    \n",
    "    def proj_u(self, u, v):\n",
    "        return self.proj_scale(u,v)*u\n",
    "    \n",
    "    def proj_scale(self, u, v):\n",
    "        if np.dot(u, u) <1e-16:\n",
    "            return 0\n",
    "        return np.dot(u, v) / np.dot(u, u)\n",
    "    \n",
    "    def gram_schmidt(self, basis): \n",
    "        cb = basis.astype(float)\n",
    "        orthobasis = np.zeros_like(cb)\n",
    "        orthobasis[0] = cb[0]\n",
    "\n",
    "        for i in range(1, len(basis)):\n",
    "            orthobasis[i] = cb[i]\n",
    "            for j in range(0, i):\n",
    "                orthobasis[i] -= self.proj_u(orthobasis[j], cb[i])\n",
    "        return orthobasis\n",
    "\n",
    "    def size_reduction(self, basis, orthobasis, k):\n",
    "        '''\n",
    "        Performs length reduction on a basis.\n",
    "        '''\n",
    "        total_m = 0 \n",
    "        for j in range(k-1, -1, -1):\n",
    "            m = int(round(self.proj_scale(orthobasis[j], basis[k])))\n",
    "            basis[k] -= m*basis[j] \n",
    "            self.R[k] -= m*self.R[j] \n",
    "            total_m += abs(m)\n",
    "\n",
    "        if total_m > 0:\n",
    "            orthobasis = self.gram_schmidt(basis)\n",
    "    \n",
    "        return basis, orthobasis\n",
    "\n",
    "    def check_lovasz_condition_and_swap(self, basis, orthobasis, k):\n",
    "        '''\n",
    "        Checks the Lovasz condition for a basis. \n",
    "        Either swaps adjacent basis vectors and recomputes Gram-Schmidt or increments the working index.\n",
    "        '''\n",
    "        c = self.delta - self.proj_scale(orthobasis[k-1], basis[k])**2\n",
    "        if orthobasis[k].dot(orthobasis[k]) >= c*orthobasis[k-1].dot(orthobasis[k-1]):\n",
    "            k += 1\n",
    "        else: \n",
    "            basis[[k, k-1]] = basis[[k-1, k]]\n",
    "            self.R[[k, k-1]] = self.R[[k-1, k]]\n",
    "            orthobasis = self.gram_schmidt(basis)\n",
    "            k = max([k-1, 1])\n",
    "        return basis, orthobasis, k\n",
    "\n",
    "    def run(self, A, verbose = True):\n",
    "        basis = A.copy()\n",
    "        self.n = A.shape[0]\n",
    "        self.m = self.n//2\n",
    "        self.R = np.identity(self.n)\n",
    "        k = 1\n",
    "        orthobasis = self.gram_schmidt(basis)\n",
    "        steps = 0\n",
    "        \n",
    "        self.init_log()\n",
    "        \n",
    "        self.maxk = k\n",
    "        while k <= basis.shape[0] - 1:\n",
    "            if steps % 5 == 0:\n",
    "                self.log(basis, k)\n",
    "            basis, orthobasis = self.size_reduction(basis, orthobasis, k)\n",
    "            steps += 1\n",
    "\n",
    "            basis, orthobasis, k = self.check_lovasz_condition_and_swap(basis, orthobasis, k)\n",
    "            if verbose:\n",
    "                print(tabulate(basis))\n",
    "                clear_output(wait=True)\n",
    "                time.sleep(0.2)\n",
    "        return basis, self.R, self.stats\n",
    "    \n",
    "    def init_log(self):\n",
    "        self.stats = dict()\n",
    "        self.stats[\"r_norms\"] = []\n",
    "        self.stats[\"ra_norms\"] = []\n",
    "        self.stats[\"k\"] = []\n",
    "        self.stats[\"delta\"] = self.delta\n",
    "        self.stats[\"N\"] = self.m\n",
    "        self.stats['q25'] = []\n",
    "        self.stats['q75'] = [] \n",
    "        self.stats['q37'] = []\n",
    "        self.stats['q62'] = []\n",
    "        \n",
    "    def log(self, basis, k):\n",
    "        if self.r: \n",
    "            R_rows = self.R[:,:self.m]\n",
    "            B_rows = basis[:,self.m:]\n",
    "        else:\n",
    "            R_rows = self.R[:,self.m:]\n",
    "            B_rows = basis[:,:self.m]\n",
    "        self.stats[\"r_norms\"].append(np.linalg.norm(R_rows, axis = 1).mean())\n",
    "        b_rows = B_rows.copy()\n",
    "        b_rows[b_rows > self.Q//2] -= self.Q\n",
    "        self.stats[\"ra_norms\"].append(np.linalg.norm(B_rows, axis = 1).mean())\n",
    "        self.maxk = max(self.maxk, k)\n",
    "        self.stats[\"k\"].append(self.maxk)\n",
    "        \n",
    "        nonQId = []\n",
    "        for row in B_rows:\n",
    "            r = row%self.Q\n",
    "            if sum(r) !=0:\n",
    "                nonQId.extend(r)\n",
    "        \n",
    "        self.stats['q25'].append(np.quantile(nonQId, q = 0.25))   \n",
    "        self.stats['q75'].append(np.quantile(nonQId, q = 0.75)) \n",
    "        self.stats['q37'].append(np.quantile(nonQId, q = 0.37))   \n",
    "        self.stats['q62'].append(np.quantile(nonQId, q = 0.62)) \n",
    "\n",
    "# Show how LLL works on A' for a N = 20 example\n",
    "lll = LLL(Q = 67, delta = 0.99)\n",
    "aa_basis, R, stats = lll.run(AA, verbose = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65df3cad",
   "metadata": {},
   "source": [
    "Now, we try to get the corresponding $b$ of these $RA$, by applying the same linear transformation on $b$. That's simply $Rb$. \n",
    "Recall that in the original LWE samples, $b$ has error, which is also linearly combined by $R$: \n",
    "\n",
    "$$Rb = R(A\\cdot s + e) = RAs + Re$$\n",
    "\n",
    "Hence, our new samples $(\\textbf{a}', b') = \\left((RA)_i, (Rb)_i\\right)$ has error $e_i' = (Rb)_i - (RA)_is = (Re)_i$. It has variance\n",
    "$\\mathbb{V}(Re) = R\\mathbb{V}(e)R^\\top = \\sigma^2 RR^\\top $. \n",
    "\n",
    "In the end, we get $2N$ samples with correlated errors, whose standard deviation is amplified by a factor of the $l_2$ norms of rows in $R$. \n",
    "\n",
    "Since acquiring $R$ is irrelevant to $b$, for the purpose of our experiments, for each $N,q$, we reuse the $A$ for different secrets in order to mitigate experiment cost. \\\n",
    "For more details on generating the datasets $(RA, Rb)$, refer to the code at src/generate/genSamples.py, the RA_Rb class. \n",
    "\n",
    "As LLL runs, the norms of $RA$ decreases (lower plot, green) and the norm of $R$ increases (lower plot, blue). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea602f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot how the 25% quantile of entries in RA (A after LLL reduction) changes as LLL runs\n",
    "x = range(len(stats['q25']))\n",
    "plt.plot(x, stats['q25'])\n",
    "plt.plot(x, Q - np.array(stats['q75']))\n",
    "plt.plot(x, 0.5*(np.array(stats['q25']) + Q - np.array(stats['q75'])))\n",
    "\n",
    "# Plot how the norm of R and RA changes as LLL runs. The norm of R is proportionate with the std of error. \n",
    "r, ra, ks = stats[\"r_norms\"], stats[\"ra_norms\"] , stats[\"k\"] \n",
    "sz = len(r)\n",
    "fig, ax1 = plt.subplots()\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "ax1.plot(range(sz), ra, 'g-') \n",
    "ax2.plot(range(sz), r, 'b-')\n",
    "# ax2.plot(range(sz), ks, 'r-', label = \"max k\")\n",
    "ax2.set_ylabel(\"mean norm of rows of R\",color='b')\n",
    "ax1.set_ylabel( \"mean norm of basis vectors\", color='g')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0cb919d",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "However, this $R$ is too large for $Re$ to have reasonable standard deviation. \n",
    "\n",
    "So, in Picante, we introduce a penalty parameter $\\omega$ in the $A'$ embedding. \n",
    "\n",
    "### Picante's data preprocessing\n",
    "Let $A' = \\begin{bmatrix}\n",
    "\\omega I_n & A \\\\\n",
    "0 & qI_n \n",
    "\\end{bmatrix}$. Then $R'A' = \\begin{bmatrix} \\omega R & RA+qC  \\end{bmatrix}$, so a larger $\\omega$ motivates a smaller $R$. \n",
    "\n",
    "And we switch to BKZ, a more advanced and more costly algorithm than LLL. Instead of projecting a vector on another, BKZ projects on the subspace spanned by a block of vectors. \n",
    "\n",
    "As shown below, a larger block size gives stronger reduction, and takes longer time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0cb37b-b302-4ae0-8699-212eed9e9f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_grids_data(path):\n",
    "    '''\n",
    "    Input: directory that stores json files\n",
    "    Output: a list of dictionaries\n",
    "    '''\n",
    "    rows = []\n",
    "    for filename in os.listdir(path):\n",
    "        if not 'N' in filename:\n",
    "            continue\n",
    "        filepath = os.path.join(path, filename)\n",
    "        stats = jd.load(filepath)\n",
    "        for key in ['A', 'R', 'RA']:\n",
    "            stats[key] = np.array(stats[key])\n",
    "\n",
    "        N, Q = stats['N'], stats['Q']\n",
    "        # Get rid of rows of all zeros\n",
    "        nonzero_ind = [i for i in range(2*N) if np.any(stats['R'][i] != 0)]\n",
    "        stats['RA'] = stats['RA'][nonzero_ind, :]\n",
    "        stats['R'] = stats['R'][nonzero_ind, :]\n",
    "        # Compute the norms\n",
    "        RA = stats['RA'].copy() % Q\n",
    "        RA[RA > Q//2] -= Q\n",
    "        stats[\"ra_norms\"] = np.linalg.norm(RA, axis = 1)\n",
    "        stats[\"r_norms\"] = np.linalg.norm(stats['R'], axis = 1)\n",
    "        rows.append(stats)\n",
    "\n",
    "    return rows\n",
    "\n",
    "def plot_grid_search(df, fixed, variables):\n",
    "    fig, axs = plt.subplots(2,3, figsize = (25, 15))\n",
    "    for k1, k2, col in [(0,0,'time'), (0,1,'mean ||R||'), (0,2,'mean ||R|| / Q'), (1,0,'mean ||RA||'), (1,1,'mean ||RA|| / Q'), (1,2,'(std RA) / Q')]: \n",
    "        x, hue = variables['x'], variables['hue']\n",
    "        ax = axs[k1, k2]\n",
    "        mean_y_per_x = df.groupby(x).agg({col: 'mean' })\n",
    "        sns.lineplot(data = mean_y_per_x, y = col, x = x, ax = ax)\n",
    "        sns.scatterplot(data = df, x = x, y = col, hue = hue, ax = ax)\n",
    "        ax.set_title(f\"{col} per {x} and {hue} \")\n",
    "    \n",
    "    title_str = ', '.join([key + ' = ' + str(val) for key, val in fixed.items()])\n",
    "    fig.suptitle(f\"BKZ reduction results for {title_str}\", fontsize=16,y=0.93)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "grid_data = pd.DataFrame(read_grids_data('/path/to/bkz/grids/N100-p15.0-d0.99-full-log'))\n",
    "grid_data = grid_data[grid_data['block_size']<25]\n",
    "\n",
    "grid_data['log2 Q'] = grid_data['Q'].apply(np.log2).apply(np.ceil)\n",
    "grid_data['mean ||R||'] = grid_data['r_norms'].apply(np.mean)\n",
    "grid_data['mean ||R|| / Q'] = grid_data['r_norms'].apply(np.mean) / grid_data['Q']\n",
    "grid_data['mean ||RA||'] = grid_data['ra_norms'].apply(np.mean)\n",
    "grid_data['mean ||RA|| / Q'] = grid_data['ra_norms'].apply(np.mean) / grid_data['Q']\n",
    "grid_data['(std RA) / Q'] = grid_data['RA'].apply(np.std) / grid_data['Q']\n",
    "\n",
    "fixed = { 'N': 100, 'delta': 0.99, 'penalty': 15.0 }\n",
    "variables = { 'x': 'block_size', 'hue': 'log2 Q' }\n",
    "plot_grid_search(grid_data, fixed, variables)\n",
    "\n",
    "def plot_RA(direc, Q):\n",
    "    agg = set()\n",
    "    for sample in read_grids_data(direc):\n",
    "        if sample['Q'] != Q or sample['block_size'] > 30:\n",
    "            continue\n",
    "        params_tuple = (sample['N'], sample['Q'], sample['penalty'], sample['delta'], sample['block_size'])\n",
    "        if params_tuple not in agg:\n",
    "            agg.add(params_tuple)\n",
    "            plt.hist(sample['ra_norms'], bins=20, label = f'bkz{sample[\"block_size\"]}')\n",
    "    plt.legend()\n",
    "    \n",
    "path = '/path/to/bkz/grids/N80-p15.0-d0.99-full-log'\n",
    "plot_RA(path, 251)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "386b8f03",
   "metadata": {},
   "source": [
    "### Visualize the distributions of the entries and the norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985f1b3e-4f66-4b74-be89-6e87ddac6e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_RA_distribution(direc, params):\n",
    "    agg, ax2lims, ax4lims = {}, {}, {}\n",
    "    for sample in read_grids_data(direc):\n",
    "        if 'block_size' not in sample: #LLL\n",
    "            sample['block_size'] = 2\n",
    "        params_tuple = (sample['N'], sample['Q'], sample['penalty'], sample['delta'], sample['block_size'])\n",
    "        if params_tuple not in agg:\n",
    "            agg[params_tuple] = sample\n",
    "            agg[params_tuple]['time'] = [sample['time']]\n",
    "        else:\n",
    "            agg[params_tuple]['RA'] = np.concatenate((agg[params_tuple]['RA'], sample['RA']))\n",
    "            agg[params_tuple]['ra_norms'] = np.concatenate((agg[params_tuple]['ra_norms'], sample['ra_norms']))\n",
    "            agg[params_tuple]['R'] = np.concatenate((agg[params_tuple]['R'], sample['R']))\n",
    "            agg[params_tuple]['r_norms'] = np.concatenate((agg[params_tuple]['r_norms'], sample['r_norms']))\n",
    "            agg[params_tuple]['time'].append(sample['time'])\n",
    "        lim1, lim2 = (min(sample['ra_norms']), max(sample['ra_norms'])), (min(sample['r_norms']), max(sample['r_norms']))\n",
    "        Q = sample['Q']\n",
    "        if Q not in ax2lims:\n",
    "            ax2lims[Q], ax4lims[Q] = lim1, lim2\n",
    "        else:\n",
    "            ax2lims[Q] = (min(ax2lims[Q][0], lim1[0]), max(ax2lims[Q][1], lim1[1]))\n",
    "            ax4lims[Q] = (min(ax4lims[Q][0], lim2[0]), max(ax4lims[Q][1], lim2[1]))\n",
    "    \n",
    "    agg = sorted(list(agg.values()), key=lambda d: [d[p] for p in params]) \n",
    "    for stats in agg:\n",
    "        stats['time'] = np.mean(stats['time'])\n",
    "        f, (ax1, ax2, ax3, ax4) = plt.subplots(1,4, figsize = (30, 5))\n",
    "        ax1.hist(stats['RA'].flatten() % stats['Q'], alpha = 0.5, bins=30);\n",
    "        ax1.set_title(', '.join([f'{key} = {stats[key]}' for key in params]))\n",
    "        ax2.hist(stats['ra_norms'], bins=20)\n",
    "        ax2.set_title('||RA||')\n",
    "        ax2.set_xlim(ax2lims[stats['Q']])\n",
    "        e = np.int64(np.random.normal(0, 3, size = stats['N']).round())\n",
    "        ax3.hist(stats['R']@e % stats['Q'], bins=20)\n",
    "        ax3.set_title('error')\n",
    "        ax4.hist(stats['r_norms'], bins=20)\n",
    "        ax4.set_title('||R||')\n",
    "        ax4.set_xlim(ax4lims[stats['Q']])\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "plot_RA_distribution('/path/to/bkz/grids/N100-p15.0-d0.99-full-log', ['Q', 'block_size', 'time'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7a319d5",
   "metadata": {},
   "source": [
    "As shown above, lattice reduction on larger Q is more effective (more obvious change on the distribution), meaning that larger Q is easier. \n",
    "### The norm of $R$ is a proxy of how much the standard deviation of the error is amplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61878645",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_distribution(grid_search_data):\n",
    "    N = grid_search_data[0]['N']\n",
    "    s = np.zeros(shape=(N, 10), dtype=np.int64)\n",
    "    for h in range(3, 13):\n",
    "        idxs = np.random.choice(N, size = h, replace=False)\n",
    "        s[idxs, h-3] = 1\n",
    "\n",
    "    stats, ra_norms, r_norms, re_norms = [], {}, {}, {}\n",
    "    for row in grid_search_data:\n",
    "        e = np.int64(np.random.normal(0, 3, size = (N, 10)).round())\n",
    "        Q = row['Q']\n",
    "        b = (row['A']@s + e) % Q\n",
    "        Rb = (row['R']@b) % Q\n",
    "        Re = (row['RA']@s - Rb) % Q\n",
    "        Re[Re > Q//2] -= Q\n",
    "        stats.append({\n",
    "            'Q': Q,\n",
    "            # 'penalty': row['penalty'], \n",
    "            'Mean ||RA||': np.mean(row['ra_norms']), \n",
    "            'Mean ||R||': np.mean(row['r_norms']), \n",
    "            'std(Re) / std(e)': np.std(Re) / np.std(e), \n",
    "            # 'Mean Re': np.mean(Re),\n",
    "            'std(Re)': np.std(Re),\n",
    "            # 'std(e)': np.std(e),\n",
    "        })\n",
    "        if Q not in ra_norms:\n",
    "            ra_norms[Q], r_norms[Q], re_norms[Q] = [],[],[]\n",
    "        ra_norms[Q].extend(row['ra_norms'])\n",
    "        r_norms[Q].extend(row['r_norms'])\n",
    "        re_norms[Q].extend(np.linalg.norm(Re, axis=1))\n",
    "    \n",
    "    f, axs = plt.subplots(2,len(r_norms.keys()), figsize = (30, 12))\n",
    "    for i,Q in enumerate(r_norms):\n",
    "        axs[0,i].scatter(r_norms[Q], ra_norms[Q], 3)\n",
    "        axs[0,i].set_title(f\"Q={Q}\")\n",
    "        axs[0,i].set_xlabel('||R||')\n",
    "        axs[0,i].set_ylabel('||RA||')\n",
    "        axs[1,i].scatter(r_norms[Q], re_norms[Q], 3)\n",
    "        axs[1,i].set_xlabel('||R||')\n",
    "        axs[1,i].set_ylabel('||Re||')\n",
    "    return pd.DataFrame(stats)\n",
    "        \n",
    "# Here we give an example to show that mean ||R|| approximates std(Re) / std(e)\n",
    "# That means, the norm of R approximates the amplification of the std of error\n",
    "path = '/path/to/bkz/grids/N80-p15.0-d0.99-full-log'\n",
    "grid_80_rlwe = read_grids_data(path)\n",
    "err_rlwe = plot_error_distribution(grid_80_rlwe)\n",
    "err_rlwe.groupby('Q').mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "44dcbb5c",
   "metadata": {},
   "source": [
    "### Statistics of RA and R are the metrics that quantify the preprocessing quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e1f437-a5b2-47f8-aad6-e44c357848ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_stats(params, data, tiny=False):\n",
    "    stats = {}\n",
    "    Q = params['Q']\n",
    "    tinyA = np.load('/path/to/tiny_A.npy')\n",
    "    for U, R in data:\n",
    "        if tiny:\n",
    "            A = tinyA[U.flatten()]\n",
    "        else:\n",
    "            A = U\n",
    "        nonzero_ind = [i for i in range(params['m']+params['N']) if np.any(R[i] != 0)]\n",
    "        R = R[nonzero_ind, :]\n",
    "        RA = (R@A) % Q\n",
    "        if 'RA' not in stats:\n",
    "            stats['RA'] = RA\n",
    "            stats['R'] = R\n",
    "            stats['nonzero'] = [len(nonzero_ind)]\n",
    "        else:\n",
    "            stats['RA'] = np.concatenate((stats['RA'], RA))\n",
    "            stats['R'] = np.concatenate((stats['R'], R))\n",
    "            stats['nonzero'].append(len(nonzero_ind))\n",
    "    RA = stats['RA']\n",
    "    RA[RA > Q//2] -= Q\n",
    "    return stats, RA\n",
    "\n",
    "def plot_hist(path):\n",
    "    params, data = read_cluster_data(path)\n",
    "    if len(data) == 0 or 'time' not in params:\n",
    "        return\n",
    "#         if params['block_size'] < 15 or params['pen'] != 15 or params['delta'] != 0.99: \n",
    "#             continue\n",
    "    stats, RA = get_data_stats(params, data)\n",
    "    f, (ax1, ax2, ax3, ax4) = plt.subplots(1,4, figsize = (30, 5))\n",
    "\n",
    "    ax1.hist(RA.flatten(), alpha = 0.5, bins=30);\n",
    "    ax1.set_title(', '.join([f'{key} = {params[key]}' for key in ['Q', 'delta', 'pen', 'block_size']]))\n",
    "\n",
    "\n",
    "    ax2.hist(np.linalg.norm(RA, axis=1), bins=20)\n",
    "    print(RA.shape)\n",
    "    ax2.set_title('||RA||')\n",
    "\n",
    "    e = np.int64(np.random.normal(0, 3, size = params['m']).round())\n",
    "    ax3.hist(np.array(stats['R'])@e % params['Q'], bins=20)\n",
    "    ax3.set_title('error')\n",
    "\n",
    "    ax4.hist(np.linalg.norm(stats['R'], axis=1), bins=20)\n",
    "    ax4.set_title('||R||')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "def save_grid_df(path, savepath=None):\n",
    "    df = []\n",
    "    for direc in os.listdir(path):\n",
    "        p = os.path.join(path, direc)\n",
    "        if len(p.split('stats'))==2:\n",
    "            continue\n",
    "        params, data = read_cluster_data(p, direc)\n",
    "        if data == None:\n",
    "            df.append(list(params.values()) + ['err'] * 3)\n",
    "        elif len(data) == 0 or 'time' not in params:\n",
    "            df.append(list(params.values()) + ['ip'] * 3)\n",
    "        else:\n",
    "            stats, RA = get_data_stats(params, data, False)\n",
    "                \n",
    "            df.append(list(params.values()) + [params['time']/np.mean(stats['nonzero']), np.sqrt(12)*np.std(RA)/params['Q'], np.mean(np.linalg.norm(stats['R'], axis=1))/params['Q']])\n",
    "    param_cols = ['xp', 'N', 'Q', 'delta', 'pen', 'float type', 'block size', 'm', 'max loop']\n",
    "    df = pd.DataFrame(df, columns = param_cols + ['time', 'time per line', 'std(RA)/std(rand)', '||R||/Q'])\n",
    "    print(f'Saving {path}')\n",
    "    if savepath:\n",
    "        df.to_csv(os.path.join(savepath, 'stats.csv'))\n",
    "    else:\n",
    "        df.to_csv(os.path.join(path, 'stats.csv'))\n",
    "\n",
    "n_grid = pd.read_csv('/path/to/stats.csv').sort_values('std(RA)/Q')\n",
    "n_grid = n_grid[n_grid['strategy'] == False]\n",
    "n_grid[n_grid['delta'] == 0.99]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9586501",
   "metadata": {},
   "source": [
    "In Picante, we select the parameters based on data frames like the one above. \n",
    "\n",
    "### Verde's data preprocessing\n",
    "Let's look at the $A'$ matrix again: $\\begin{bmatrix}\n",
    "\\omega I_n & A \\\\\n",
    "0 & qI_n \n",
    "\\end{bmatrix}$. \\\n",
    "The Q identity matrix are orthogonal, so if they are put first, there will be no projections on the first n rows, which should save time. \\\n",
    "Also, this way, when we reach the $A$, it would slide up and project with $qI_n$, so norm reduction is aided with mod Q\n",
    "instead of just struggling to get short vectors using A without mod Q for a long time. \\\n",
    "In Verde, we rearrange the rows of $A'$: $\\begin{bmatrix}\n",
    "0 & qI_n \\\\\n",
    "\\omega I_n & A\n",
    "\\end{bmatrix}$. \\\n",
    "We use a even more efficient algorithm: BKZ 2.0 interleaved with Mark's new lattice reduction algo. Also, we introduce a large blocksize + early termination strategy. \\\n",
    "This is from the observation that most of the norm reduction is done in the first few loops of BKZ, as shown below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1727c4b9-cba6-4e01-b8e2-2aaaedc4b57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_grid = pd.read_csv('/path/to/n256_qfirst_loop/stats.csv').sort_values('max loop')\n",
    "# n_grid = n_grid[n_grid['autoAbort'] == False]\n",
    "# n_grid = n_grid[n_grid['strategy'] == False]\n",
    "# n_grid = n_grid[n_grid['pen'] == 10]\n",
    "n_grid = n_grid[n_grid['float type'] == 'dd']\n",
    "n_grid = n_grid[n_grid['max loop'] < 9999]\n",
    "display(n_grid)\n",
    "plt.scatter([0]+n_grid['time'].tolist(), [1]+n_grid['std(RA)/std(rand)'].tolist(), s=10)\n",
    "plt.xlabel('time') # minutes to generate one line\n",
    "plt.ylabel('stddev/q')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d111967a",
   "metadata": {},
   "source": [
    "### After Verde\n",
    "Verde uses a lot of cpus. When processing 1 matrix, it only gets $2N$ samples at the end after hours or days of lattice reduction. \\\n",
    "So here's a new improvement: we start writing data once the norm reaches some threshold very close to the target, and let it run for a while (during which we keep writing data), \n",
    "so we harvest $\\gg$2n samples from each matrix preprocessing. \n",
    "\n",
    "For more details, refer to the implementation at src/generate/genSamples.py, the BKZReducedLWE class. \n",
    "\n",
    "We also added support to RLWE. \\\n",
    "Let $R_q = \\mathbb{Z}_q[x]/(x^n+1)$ be the set of polynomials whose degree is at most $n-1$ and coefficients are from $\\mathbb{Z}_q$. \\\n",
    "An RLWE sample $(a(x), b(x): = a(x)\\cdot s(x) + e(x))$ has coefficients $\\textbf{a} \\sim U(\\mathbb{Z}_q^N)$\n",
    ", $s(x) \\in R_q$  is the secret and $e(x) \\in R_q$ is the error. \\\n",
    "Equivalently, using vectors to represent the coefficients of the polynomials, we have $\\textbf{b} = \\textbf{A}^{circ}\\cdot \\textbf{s} + \\textbf{e}$. \n",
    "\n",
    "Our data preprocessing preserve the circulant as follows:\\\n",
    "We take the first row of a list of circulant matrices to construct $A$, and reduce it (i.e., obtain the $R$ matrix). \\\n",
    "The norm is invariant on swapping or negating elements (which is what the circulant does to the rows), so apply the same linear transformation to the other rows of the matrices, would result in small norms as well. \\\n",
    "Since linear combination and taking the circulant are associative, we end up with circulant matrices from the reduced vectors. \\\n",
    "To get the corresponding $Rb$ of $(RA)_i^{circ}$, we just need to apply $R$ on the $b$ of other rows of $A^{circ}$. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "efb62c75",
   "metadata": {},
   "source": [
    "# uSVP attack\n",
    "With $m$ LWE samples, we can construct matrix $A_{m\\times N}$ by stacking the vectors as rows. Kannan's embedding is constructed as follows: $\\begin{pmatrix}\n",
    "I_n & A^T & 0\\\\\n",
    "0 & qI_m & 0 \\\\\n",
    "0 & b & 1\n",
    "\\end{pmatrix}$\n",
    "\n",
    "An unusually short vector $\\begin{pmatrix} s & -e & -1\\end{pmatrix}$ is in the space spanned by these rows, since $\\begin{pmatrix}\n",
    "s & c & -1\n",
    "\\end{pmatrix}\\begin{pmatrix}\n",
    "I_n & A^T & 0\\\\\n",
    "0 & qI_m & 0 \\\\\n",
    "0 & b & 1\n",
    "\\end{pmatrix}  = \\begin{pmatrix}\n",
    "s & A \\cdot s + qc - b & -1\n",
    "\\end{pmatrix}$.\n",
    "\n",
    "In practice, the $I_n$ is multiplied by a parameter $\\omega$ to balance $s$ and $-e$. \\\n",
    "For more details, refer to the implementation at src/generate/genSamples.py, the BenchmarkBKZ class. \\\n",
    "The parameters used by the paper \"On the concrete security of lwe with small secret\" can be reproduced below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe149d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_delta_d(n, logq, sigma):\n",
    "    q = 2**logq\n",
    "    w = np.round(sigma * np.sqrt(2))\n",
    "    d = 2*n*np.log(q/w)/np.log(q/(np.sqrt(2*np.pi*np.e)*sigma))\n",
    "    d_int = np.ceil(d)\n",
    "    logdelta = np.log(q/(np.sqrt(2*np.pi*np.e)*sigma)) ** 2 / (4*n*np.log(q/w))\n",
    "    return(d_int, np.round(np.e**logdelta, 4))\n",
    "\n",
    "compute_delta_d(80, 9, 3.2), compute_delta_d(150, 15, 3.2), compute_delta_d(200, 19, 3.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91d8fbe8",
   "metadata": {},
   "source": [
    "Here's a new idea: if we just row reduce the right part of the matrix $\\begin{pmatrix}\n",
    "A^T \\\\ qI_m \\\\ b \n",
    "\\end{pmatrix}$, we will still end up with an unusually short vector $e$ or $-e$. Then, we can subtract $e$ from $b$ to get the $A\\cdot s$ without error. \\\n",
    "Now it is very vulnerable to algebraic attacks. Modular diagonalization can recover the secret as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65f1f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "N, Q = 20, 251\n",
    "Ab = np.zeros((N+2, N+1))\n",
    "A = np.random.randint(0,Q,size=(N+2,N))\n",
    "s = np.random.normal(0,3, size = N).astype(int)\n",
    "Ab[:,:N] = A\n",
    "Ab[:,-1] = A@s%Q\n",
    "\n",
    "for i in range(N):\n",
    "    k = 1\n",
    "    while Ab[i,i] == 0:\n",
    "        # it doesn't have an inverse. Swap with another row.\n",
    "        Ab[i], Ab[i+k] = Ab[i+k], Ab[i]\n",
    "        k += 1\n",
    "    Ab[i] *= pow(int(Ab[i,i]), -1, Q) # this algo is in integer space. Multiply with the modular inverse\n",
    "    Ab[i] %= Q\n",
    "    for j in range(N):\n",
    "        if i==j:\n",
    "            continue\n",
    "        Ab[j] -= Ab[j][i] * Ab[i] # gaussian elimination to diagonalize the matrix\n",
    "        Ab[j] %= Q\n",
    "s_solved = Ab[:N, -1]\n",
    "s_solved[s_solved>Q//2] -=Q\n",
    "\n",
    "np.all(s == s_solved)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d59ba32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a1b9ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
